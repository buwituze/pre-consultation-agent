{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buwituze/pre-consultation-agent/blob/main/language_understanding_model_b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "title-cell",
      "metadata": {
        "id": "title-cell"
      },
      "source": [
        "# üß† Model B ‚Äî Language Understanding (Text ‚Üí Structured Meaning)\n",
        "\n",
        "**Purpose:** Extract structured, clinically relevant information from patient speech transcripts to support triage and downstream reasoning.\n",
        "\n",
        "| | |\n",
        "|---|---|\n",
        "| **Input** | Cleaned text transcript (output from Model A) |\n",
        "| **Output** | Fixed-schema JSON + `additional_observations` field |\n",
        "| **Model** | Google Gemini AI (via `google-generativeai`) |\n",
        "| **Mode** | Constrained information extraction ‚Äî no diagnosis, no advice |\n",
        "\n",
        "### Pipeline Position\n",
        "```\n",
        "Model A Output                     Model B Output\n",
        "(Transcript Text)\n",
        "       ‚îÇ\n",
        "       ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  Transcript +       ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  chief_complaint              ‚îÇ\n",
        "‚îÇ  Fixed Schema       ‚îÇ       ‚îÇ  duration                     ‚îÇ\n",
        "‚îÇ  (prompt)           ‚îÇ       ‚îÇ  severity                     ‚îÇ\n",
        "‚îÇ                     ‚îÇ       ‚îÇ  body_part                    ‚îÇ\n",
        "‚îÇ  Gemini Model       ‚îÇ       ‚îÇ  associated_symptoms []       ‚îÇ\n",
        "‚îÇ                     ‚îÇ       ‚îÇ  red_flags_present true/false ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ  additional_observations      ‚îÇ\n",
        "                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                                         ‚îÇ\n",
        "                                         ‚ñº\n",
        "                                    ‚Üí Model C (Dialogue)\n",
        "                                    ‚Üí Doctor Review\n",
        "```\n",
        "\n",
        "> ‚ö†Ô∏è **Non-Negotiable Constraints:** This model produces **observational output only**. No diagnoses, no medical advice, no treatment or medication recommendations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-1",
      "metadata": {
        "id": "section-1"
      },
      "source": [
        "---\n",
        "## üì¶ Section 1 ‚Äî Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "install",
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai\n",
        "!pip install -q jsonschema\n",
        "\n",
        "print(\"‚úÖ Dependencies installed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-2",
      "metadata": {
        "id": "section-2"
      },
      "source": [
        "---\n",
        "## üîë Section 2 ‚Äî API Key Configuration\n",
        "\n",
        "Store your Gemini API key securely using **Colab Secrets** (the üîë icon in the left sidebar) under the name `GEMINI_API_KEY`. This avoids hardcoding credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "api-key",
      "metadata": {
        "id": "api-key"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# ‚îÄ‚îÄ Load API key from Colab Secrets ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# Add your key via: left sidebar ‚Üí üîë Secrets ‚Üí Add \"GEMINI_API_KEY\"\n",
        "try:\n",
        "    GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "    genai.configure(api_key=GEMINI_API_KEY)\n",
        "    print(\"‚úÖ Gemini API key loaded from Colab Secrets.\")\n",
        "except Exception:\n",
        "    # Fallback: paste key directly (not recommended for shared notebooks)\n",
        "    GEMINI_API_KEY = \"YOUR_API_KEY_HERE\"  # ‚Üê replace only if Secrets unavailable\n",
        "    genai.configure(api_key=GEMINI_API_KEY)\n",
        "    print(\"‚ö†Ô∏è  API key set manually. Use Colab Secrets for security.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-3",
      "metadata": {
        "id": "section-3"
      },
      "source": [
        "---\n",
        "## ü§ñ Section 3 ‚Äî Model Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "model-init",
      "metadata": {
        "id": "model-init"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "from dataclasses import dataclass, field, asdict\n",
        "from typing import List, Optional\n",
        "\n",
        "# ‚îÄ‚îÄ Model configuration ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# gemini-1.5-flash: fast, cost-efficient, supports multilingual text well\n",
        "# gemini-1.5-pro  : higher reasoning quality ‚Äî swap in for production\n",
        "GEMINI_MODEL_NAME = \"gemini-1.5-flash\"\n",
        "\n",
        "generation_config = genai.types.GenerationConfig(\n",
        "    temperature       = 0.0,    # Deterministic ‚Äî critical for consistent schema output\n",
        "    top_p             = 1.0,\n",
        "    max_output_tokens = 1024,   # Schema output is compact; 1024 is sufficient\n",
        ")\n",
        "\n",
        "safety_settings = [\n",
        "    # Relax Gemini's default blocks on medical content so clinical terms pass through\n",
        "    {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",  \"threshold\": \"BLOCK_ONLY_HIGH\"},\n",
        "    {\"category\": \"HARM_CATEGORY_HARASSMENT\",         \"threshold\": \"BLOCK_ONLY_HIGH\"},\n",
        "    {\"category\": \"HARM_CATEGORY_HATE_SPEECH\",        \"threshold\": \"BLOCK_ONLY_HIGH\"},\n",
        "    {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",  \"threshold\": \"BLOCK_ONLY_HIGH\"},\n",
        "]\n",
        "\n",
        "gemini_model = genai.GenerativeModel(\n",
        "    model_name        = GEMINI_MODEL_NAME,\n",
        "    generation_config = generation_config,\n",
        "    safety_settings   = safety_settings,\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Gemini model initialised: {GEMINI_MODEL_NAME}\")\n",
        "print(f\"   Temperature : {generation_config.temperature} (deterministic)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-4",
      "metadata": {
        "id": "section-4"
      },
      "source": [
        "---\n",
        "## üìê Section 4 ‚Äî Output Schema Definition\n",
        "\n",
        "The schema is the contract between the model and downstream systems. It is fixed and passed directly into the prompt ‚Äî Gemini is instructed to populate it, not design it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "schema",
      "metadata": {
        "id": "schema"
      },
      "outputs": [],
      "source": [
        "# ‚îÄ‚îÄ Dataclass for strongly-typed output ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "@dataclass\n",
        "class ClinicalExtraction:\n",
        "    \"\"\"\n",
        "    Structured output from Model B.\n",
        "    All fields are observational ‚Äî no diagnosis, no advice.\n",
        "    \"\"\"\n",
        "    chief_complaint         : str         = \"\"       # Main reason for visit\n",
        "    duration                : str         = \"\"       # How long the symptom has been present\n",
        "    severity                : str         = \"\"       # Patient's own description (mild/moderate/severe)\n",
        "    body_part               : str         = \"\"       # Anatomical area mentioned\n",
        "    associated_symptoms     : List[str]   = field(default_factory=list)  # Secondary symptoms\n",
        "    red_flags_present       : Optional[bool] = None  # True if any red flag language detected\n",
        "    additional_observations : str         = \"\"       # Unstructured but clinically relevant context\n",
        "\n",
        "\n",
        "# ‚îÄ‚îÄ Empty schema template (injected into prompt) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "EMPTY_SCHEMA = {\n",
        "    \"chief_complaint\"         : \"\",\n",
        "    \"duration\"                : \"\",\n",
        "    \"severity\"                : \"\",\n",
        "    \"body_part\"               : \"\",\n",
        "    \"associated_symptoms\"     : [],\n",
        "    \"red_flags_present\"       : None,\n",
        "    \"additional_observations\" : \"\"\n",
        "}\n",
        "\n",
        "# ‚îÄ‚îÄ Red flag vocabulary ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# Used for schema validation ‚Äî Gemini's red_flags_present is cross-checked\n",
        "RED_FLAG_TERMS = [\n",
        "    # English\n",
        "    \"can't breathe\", \"cannot breathe\", \"chest pain\", \"chest tightness\",\n",
        "    \"unconscious\", \"fainted\", \"fainting\", \"collapse\", \"collapsed\",\n",
        "    \"severe bleeding\", \"heavy bleeding\", \"coughing blood\", \"blood in urine\",\n",
        "    \"stroke\", \"paralysis\", \"can't move\", \"cannot move\",\n",
        "    \"seizure\", \"convulsion\", \"fits\",\n",
        "    \"sudden vision loss\", \"sudden blindness\",\n",
        "    \"difficulty swallowing\", \"can't swallow\",\n",
        "    # Kinyarwanda transliterations (common terms)\n",
        "    \"guhumeka\",        # breathing\n",
        "    \"amaraso\",         # blood\n",
        "    \"guhinduka\",       # collapse / change suddenly\n",
        "    \"ingufu\",          # convulsion / force\n",
        "    \"kunanirwa\",       # unable to\n",
        "    \"imitsi\",          # paralysis / nerves\n",
        "]\n",
        "\n",
        "print(\"‚úÖ Output schema and red flag vocabulary defined.\")\n",
        "print(f\"   Schema fields : {list(EMPTY_SCHEMA.keys())}\")\n",
        "print(f\"   Red flag terms: {len(RED_FLAG_TERMS)} terms loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-5",
      "metadata": {
        "id": "section-5"
      },
      "source": [
        "---\n",
        "## üìù Section 5 ‚Äî Prompt Engineering\n",
        "\n",
        "The system prompt and user prompt are separated. The system prompt establishes role, constraints, and output rules once. The user prompt injects the transcript at runtime.\n",
        "\n",
        "Design principles applied:\n",
        "- **Strict JSON-only output** ‚Äî no prose, no markdown fences\n",
        "- **Leave blank, never invent** ‚Äî missing fields stay empty\n",
        "- **Hard constraint block** ‚Äî no diagnosis, no advice, no recommendations\n",
        "- **Multilingual awareness** ‚Äî Kinyarwanda, English, and mixed text are all valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "prompts",
      "metadata": {
        "id": "prompts"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = \"\"\"\\\n",
        "You are a clinical information extraction assistant operating in a hospital triage system.\n",
        "Your ONLY job is to extract factual, observable information from patient speech transcripts\n",
        "and populate a fixed JSON schema.\n",
        "\n",
        "=== HARD CONSTRAINTS (NEVER VIOLATE) ===\n",
        "- Do NOT generate any diagnosis, suspected condition, or differential.\n",
        "- Do NOT provide medical advice, treatment suggestions, or medication recommendations.\n",
        "- Do NOT infer or guess information not present in the transcript.\n",
        "- Do NOT add new fields to the schema.\n",
        "- Do NOT wrap your output in markdown code blocks or backticks.\n",
        "- Your output must be a single, valid JSON object and nothing else.\n",
        "\n",
        "=== OUTPUT RULES ===\n",
        "1. Populate fields ONLY with information explicitly stated or directly implied in the transcript.\n",
        "2. Leave a field as an empty string \"\" or empty list [] if information is absent or unclear.\n",
        "3. \"red_flags_present\": set to true if the patient mentions any of these ‚Äî difficulty breathing,\n",
        "   chest pain, loss of consciousness, heavy bleeding, seizure, sudden paralysis, or inability\n",
        "   to perform a basic function. Set to false if none apply. Set to null if genuinely unclear.\n",
        "4. \"additional_observations\": capture any clinically relevant context that doesn't fit other\n",
        "   fields (e.g. emotional state, environmental context, patient's own worry, language used).\n",
        "   Keep it concise and factual. Do not include observations about the recording quality.\n",
        "5. \"severity\": use the patient's own words or phrasing. Do not reclassify.\n",
        "6. The transcript may be in English, Kinyarwanda, or a mix of both. Extract from all languages.\n",
        "\n",
        "=== SCHEMA TO POPULATE ===\n",
        "{schema}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def build_user_prompt(transcript: str) -> str:\n",
        "    \"\"\"Construct the user-turn prompt for a given transcript.\"\"\"\n",
        "    return f\"\"\"\\\n",
        "=== PATIENT TRANSCRIPT ===\n",
        "{transcript.strip()}\n",
        "\n",
        "=== TASK ===\n",
        "Extract information from the transcript above and return ONLY the populated JSON schema.\n",
        "Do not include any text before or after the JSON object.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "print(\"‚úÖ Prompt templates defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-6",
      "metadata": {
        "id": "section-6"
      },
      "source": [
        "---\n",
        "## ‚öôÔ∏è Section 6 ‚Äî Output Parsing & Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "parsing",
      "metadata": {
        "id": "parsing"
      },
      "outputs": [],
      "source": [
        "def parse_gemini_response(raw_text: str) -> dict:\n",
        "    \"\"\"\n",
        "    Parse the raw Gemini response into a Python dict.\n",
        "    Handles edge cases: markdown fences, leading/trailing whitespace,\n",
        "    and truncated responses.\n",
        "    \"\"\"\n",
        "    # Strip markdown fences if Gemini adds them despite instruction\n",
        "    cleaned = re.sub(r\"```(?:json)?\\s*\", \"\", raw_text).strip()\n",
        "    cleaned = re.sub(r\"```\\s*$\", \"\", cleaned).strip()\n",
        "\n",
        "    # Extract the first JSON object found\n",
        "    match = re.search(r\"\\{.*\\}\", cleaned, re.DOTALL)\n",
        "    if not match:\n",
        "        raise ValueError(f\"No JSON object found in model response.\\nRaw: {raw_text[:300]}\")\n",
        "\n",
        "    return json.loads(match.group(0))\n",
        "\n",
        "\n",
        "def validate_and_coerce(raw_dict: dict) -> ClinicalExtraction:\n",
        "    \"\"\"\n",
        "    Validate model output against the schema.\n",
        "    Coerces types, fills missing keys, and cross-validates red_flags_present\n",
        "    against the known red flag vocabulary.\n",
        "\n",
        "    Returns a ClinicalExtraction dataclass instance.\n",
        "    \"\"\"\n",
        "    # ‚îÄ‚îÄ Ensure all keys are present ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "    validated = {k: raw_dict.get(k, v) for k, v in EMPTY_SCHEMA.items()}\n",
        "\n",
        "    # ‚îÄ‚îÄ Type coercion ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "    # String fields\n",
        "    for str_field in [\"chief_complaint\", \"duration\", \"severity\",\n",
        "                      \"body_part\", \"additional_observations\"]:\n",
        "        if not isinstance(validated[str_field], str):\n",
        "            validated[str_field] = str(validated[str_field]) if validated[str_field] else \"\"\n",
        "\n",
        "    # List field\n",
        "    if not isinstance(validated[\"associated_symptoms\"], list):\n",
        "        val = validated[\"associated_symptoms\"]\n",
        "        validated[\"associated_symptoms\"] = [val] if val else []\n",
        "\n",
        "    # Boolean / null field\n",
        "    rfp = validated[\"red_flags_present\"]\n",
        "    if rfp not in (True, False, None):\n",
        "        validated[\"red_flags_present\"] = None\n",
        "\n",
        "    # ‚îÄ‚îÄ Cross-validate red_flags_present with vocabulary ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "    all_text = \" \".join([\n",
        "        validated[\"chief_complaint\"],\n",
        "        validated[\"additional_observations\"],\n",
        "        \" \".join(validated[\"associated_symptoms\"]),\n",
        "    ]).lower()\n",
        "\n",
        "    keyword_hit = any(term.lower() in all_text for term in RED_FLAG_TERMS)\n",
        "\n",
        "    # If vocabulary detects red flag but model missed it, override to True\n",
        "    if keyword_hit and validated[\"red_flags_present\"] is not True:\n",
        "        validated[\"red_flags_present\"] = True\n",
        "        print(\"  ‚ö†Ô∏è  Red flag keyword detected ‚Äî overriding model output to True.\")\n",
        "\n",
        "    return ClinicalExtraction(**validated)\n",
        "\n",
        "\n",
        "print(\"‚úÖ Parsing and validation functions defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-7",
      "metadata": {
        "id": "section-7"
      },
      "source": [
        "---\n",
        "## üöÄ Section 7 ‚Äî Core Extraction Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "extraction-pipeline",
      "metadata": {
        "id": "extraction-pipeline"
      },
      "outputs": [],
      "source": [
        "def extract_clinical_information(\n",
        "    transcript        : str,\n",
        "    source_language   : str = \"unknown\",\n",
        "    source_confidence : float = 1.0,\n",
        "    verbose           : bool = True,\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Full Model B pipeline: transcript ‚Üí structured clinical extraction.\n",
        "\n",
        "    Args:\n",
        "        transcript        : Raw text from Model A (any language).\n",
        "        source_language   : Language reported by Model A ('kinyarwanda'/'english'/'unknown').\n",
        "        source_confidence : Confidence score from Model A (0.0‚Äì1.0).\n",
        "        verbose           : Print progress and results.\n",
        "\n",
        "    Returns:\n",
        "        dict with keys:\n",
        "            'extraction'          : ClinicalExtraction dataclass\n",
        "            'extraction_dict'     : dict version of extraction\n",
        "            'source_language'     : str\n",
        "            'source_confidence'   : float\n",
        "            'raw_model_response'  : str (for debugging)\n",
        "            'extraction_success'  : bool\n",
        "            'error'               : str or None\n",
        "    \"\"\"\n",
        "    if verbose:\n",
        "        print(\"\\n\" + \"‚ïê\" * 62)\n",
        "        print(\" üß†  LANGUAGE UNDERSTANDING PIPELINE ‚Äî MODEL B\")\n",
        "        print(\"‚ïê\" * 62)\n",
        "        print(f\"  Source language   : {source_language}\")\n",
        "        print(f\"  Source confidence : {source_confidence:.3f}\")\n",
        "        preview = transcript.strip()[:120]\n",
        "        print(f\"  Transcript preview: {preview}{'...' if len(transcript) > 120 else ''}\")\n",
        "\n",
        "    # ‚îÄ‚îÄ Guard: refuse to process near-empty transcripts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "    if len(transcript.strip()) < 10:\n",
        "        if verbose:\n",
        "            print(\"  ‚ùå Transcript too short to extract information.\")\n",
        "        empty = ClinicalExtraction()\n",
        "        return {\n",
        "            \"extraction\"         : empty,\n",
        "            \"extraction_dict\"    : asdict(empty),\n",
        "            \"source_language\"    : source_language,\n",
        "            \"source_confidence\"  : source_confidence,\n",
        "            \"raw_model_response\" : \"\",\n",
        "            \"extraction_success\" : False,\n",
        "            \"error\"              : \"Transcript too short.\",\n",
        "        }\n",
        "\n",
        "    # ‚îÄ‚îÄ Build prompt ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "    system_with_schema = SYSTEM_PROMPT.format(\n",
        "        schema=json.dumps(EMPTY_SCHEMA, indent=2)\n",
        "    )\n",
        "    user_prompt = build_user_prompt(transcript)\n",
        "\n",
        "    # ‚îÄ‚îÄ Call Gemini ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "    try:\n",
        "        if verbose:\n",
        "            print(\"\\n  üîÑ Calling Gemini API...\")\n",
        "\n",
        "        chat = gemini_model.start_chat(history=[\n",
        "            {\"role\": \"user\",  \"parts\": [system_with_schema]},\n",
        "            {\"role\": \"model\", \"parts\": [\"Understood. I will extract information from transcripts and return only valid JSON matching the provided schema, without diagnosis or medical advice.\"]},\n",
        "        ])\n",
        "        response     = chat.send_message(user_prompt)\n",
        "        raw_response = response.text\n",
        "\n",
        "        if verbose:\n",
        "            print(\"  ‚úÖ Gemini response received.\")\n",
        "\n",
        "    except Exception as api_err:\n",
        "        err_msg = str(api_err)\n",
        "        if verbose:\n",
        "            print(f\"  ‚ùå Gemini API error: {err_msg}\")\n",
        "        empty = ClinicalExtraction()\n",
        "        return {\n",
        "            \"extraction\"         : empty,\n",
        "            \"extraction_dict\"    : asdict(empty),\n",
        "            \"source_language\"    : source_language,\n",
        "            \"source_confidence\"  : source_confidence,\n",
        "            \"raw_model_response\" : \"\",\n",
        "            \"extraction_success\" : False,\n",
        "            \"error\"              : err_msg,\n",
        "        }\n",
        "\n",
        "    # ‚îÄ‚îÄ Parse and validate ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "    try:\n",
        "        raw_dict   = parse_gemini_response(raw_response)\n",
        "        extraction = validate_and_coerce(raw_dict)\n",
        "        success    = True\n",
        "        error      = None\n",
        "    except Exception as parse_err:\n",
        "        if verbose:\n",
        "            print(f\"  ‚ö†Ô∏è  Parse error: {parse_err}\")\n",
        "        extraction = ClinicalExtraction()\n",
        "        success    = False\n",
        "        error      = str(parse_err)\n",
        "\n",
        "    # ‚îÄ‚îÄ Display results ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "    if verbose and success:\n",
        "        print(\"\\n\" + \"‚îÄ\" * 62)\n",
        "        print(\" üìã  EXTRACTION RESULT\")\n",
        "        print(\"‚îÄ\" * 62)\n",
        "        d = asdict(extraction)\n",
        "        for key, value in d.items():\n",
        "            display_val = value if value not in (\"\", [], None) else \"‚¨ú (not found)\"\n",
        "            print(f\"  {key:<28}: {display_val}\")\n",
        "        if extraction.red_flags_present:\n",
        "            print(\"\\n  üö® RED FLAG DETECTED ‚Äî escalate for immediate review.\")\n",
        "\n",
        "    return {\n",
        "        \"extraction\"         : extraction,\n",
        "        \"extraction_dict\"    : asdict(extraction),\n",
        "        \"source_language\"    : source_language,\n",
        "        \"source_confidence\"  : source_confidence,\n",
        "        \"raw_model_response\" : raw_response,\n",
        "        \"extraction_success\" : success,\n",
        "        \"error\"              : error,\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"‚úÖ Core extraction pipeline defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-8",
      "metadata": {
        "id": "section-8"
      },
      "source": [
        "---\n",
        "## üîó Section 8 ‚Äî Model A ‚Üí Model B Integration\n",
        "\n",
        "This is the standard runtime flow when Models A and B are chained together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "integration",
      "metadata": {
        "id": "integration"
      },
      "outputs": [],
      "source": [
        "def run_pipeline_from_model_a(model_a_output: dict, verbose: bool = True) -> dict:\n",
        "    \"\"\"\n",
        "    Accept the full output dict from Model A (transcribe_audio_file)\n",
        "    and feed it directly into Model B.\n",
        "\n",
        "    Args:\n",
        "        model_a_output : Dict returned by `transcribe_audio_file()` from Model A.\n",
        "        verbose        : Print pipeline progress.\n",
        "\n",
        "    Returns:\n",
        "        Model B output dict (same structure as extract_clinical_information).\n",
        "    \"\"\"\n",
        "    transcript  = model_a_output.get(\"full_text\", \"\")\n",
        "    language    = model_a_output.get(\"dominant_language\", \"unknown\")\n",
        "    confidence  = model_a_output.get(\"mean_confidence\", 1.0)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"üîó Receiving Model A output...\")\n",
        "        print(f\"   Language   : {language}\")\n",
        "        print(f\"   Confidence : {confidence:.3f}\")\n",
        "        print(f\"   Transcript : {transcript[:100]}...\" if len(transcript) > 100 else f\"   Transcript : {transcript}\")\n",
        "\n",
        "    return extract_clinical_information(\n",
        "        transcript        = transcript,\n",
        "        source_language   = language,\n",
        "        source_confidence = confidence,\n",
        "        verbose           = verbose,\n",
        "    )\n",
        "\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# USAGE (when Model A notebook is also open / imported):\n",
        "#\n",
        "#   # Model A\n",
        "#   model_a_result = transcribe_audio_file(\"patient_audio.wav\")\n",
        "#\n",
        "#   # Model B ‚Äî chain directly\n",
        "#   model_b_result = run_pipeline_from_model_a(model_a_result)\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "\n",
        "print(\"‚úÖ Model A ‚Üí Model B integration function defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-9",
      "metadata": {
        "id": "section-9"
      },
      "source": [
        "---\n",
        "## üß™ Section 9 ‚Äî Test Cases\n",
        "\n",
        "Run these to validate the pipeline before connecting to real audio. Covers English, Kinyarwanda, mixed language, a red flag case, and a sparse/minimal transcript."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "test-cases",
      "metadata": {
        "id": "test-cases"
      },
      "outputs": [],
      "source": [
        "TEST_CASES = [\n",
        "    {\n",
        "        \"id\"         : \"TC-01 | English ‚Äî standard presentation\",\n",
        "        \"language\"   : \"english\",\n",
        "        \"confidence\" : 0.91,\n",
        "        \"transcript\" : \"\"\"\n",
        "            I've had a headache for the past three days. It's mostly on the right side of my head.\n",
        "            The pain is moderate, maybe a six out of ten. I also feel a bit nauseous, and\n",
        "            light seems to make it worse. I took paracetamol yesterday but it didn't help much.\n",
        "        \"\"\",\n",
        "    },\n",
        "    {\n",
        "        \"id\"         : \"TC-02 | Kinyarwanda ‚Äî abdominal symptoms\",\n",
        "        \"language\"   : \"kinyarwanda\",\n",
        "        \"confidence\" : 0.84,\n",
        "        \"transcript\" : \"\"\"\n",
        "            Ndi n'ububabare mu nda kuva ejo. Ububabare ni uburemere kandi burarushaho.\n",
        "            Sinashye neza ijoro rya ejo. Nk'aho mba nshaka kuruka ariko sinabikora.\n",
        "        \"\"\",\n",
        "        # Translation hint: Stomach pain since yesterday. Heavy pain, getting worse.\n",
        "        # Couldn't sleep last night. Feels like vomiting but hasn't.\n",
        "    },\n",
        "    {\n",
        "        \"id\"         : \"TC-03 | Mixed language ‚Äî code-switching\",\n",
        "        \"language\"   : \"kinyarwanda\",\n",
        "        \"confidence\" : 0.77,\n",
        "        \"transcript\" : \"\"\"\n",
        "            Chest pain yatangiye ejobundi. Ndi kwibaza niba ni heart problem.\n",
        "            Ntushobora guhumeka neza iyo ugerageza gukora akazi.\n",
        "            The pain shoots to my left arm sometimes.\n",
        "        \"\"\",\n",
        "        # Translation hint: Chest pain started two days ago. Wondering if it's a heart problem.\n",
        "        # Can't breathe well when trying to work. Pain goes to left arm.\n",
        "    },\n",
        "    {\n",
        "        \"id\"         : \"TC-04 | English ‚Äî sparse transcript\",\n",
        "        \"language\"   : \"english\",\n",
        "        \"confidence\" : 0.60,\n",
        "        \"transcript\" : \"My leg hurts.\",\n",
        "    },\n",
        "    {\n",
        "        \"id\"         : \"TC-05 | English ‚Äî red flag case\",\n",
        "        \"language\"   : \"english\",\n",
        "        \"confidence\" : 0.95,\n",
        "        \"transcript\" : \"\"\"\n",
        "            I suddenly can't see properly out of my left eye. It started about an hour ago.\n",
        "            I also feel very confused and my right arm feels weak. I've never had this before.\n",
        "        \"\"\",\n",
        "    },\n",
        "]\n",
        "\n",
        "print(f\"‚úÖ {len(TEST_CASES)} test cases loaded. Run the next cell to execute them.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "run-tests",
      "metadata": {
        "id": "run-tests"
      },
      "outputs": [],
      "source": [
        "# ‚îÄ‚îÄ Run all test cases ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "test_results = {}\n",
        "\n",
        "for tc in TEST_CASES:\n",
        "    print(f\"\\n{'‚ñì' * 62}\")\n",
        "    print(f\"  TEST CASE: {tc['id']}\")\n",
        "    print(f\"{'‚ñì' * 62}\")\n",
        "\n",
        "    result = extract_clinical_information(\n",
        "        transcript        = tc[\"transcript\"],\n",
        "        source_language   = tc[\"language\"],\n",
        "        source_confidence = tc[\"confidence\"],\n",
        "        verbose           = True,\n",
        "    )\n",
        "    test_results[tc[\"id\"]] = result\n",
        "\n",
        "print(f\"\\n\\n‚úÖ All {len(TEST_CASES)} test cases completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-10",
      "metadata": {
        "id": "section-10"
      },
      "source": [
        "---\n",
        "## üóÇÔ∏è Section 10 ‚Äî Batch Processing & Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "batch",
      "metadata": {
        "id": "batch"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "def batch_extract(\n",
        "    transcripts : list,\n",
        "    verbose     : bool = False,\n",
        ") -> list:\n",
        "    \"\"\"\n",
        "    Batch process a list of transcript dicts.\n",
        "\n",
        "    Each item in `transcripts` should have:\n",
        "        {\n",
        "          'transcript'       : str,\n",
        "          'source_language'  : str,   (optional)\n",
        "          'source_confidence': float  (optional)\n",
        "        }\n",
        "\n",
        "    Returns:\n",
        "        List of Model B output dicts.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    total   = len(transcripts)\n",
        "    for i, item in enumerate(transcripts):\n",
        "        print(f\"  [{i+1}/{total}] Processing transcript...\")\n",
        "        res = extract_clinical_information(\n",
        "            transcript        = item.get(\"transcript\", \"\"),\n",
        "            source_language   = item.get(\"source_language\", \"unknown\"),\n",
        "            source_confidence = item.get(\"source_confidence\", 1.0),\n",
        "            verbose           = verbose,\n",
        "        )\n",
        "        res[\"input_transcript\"] = item.get(\"transcript\", \"\")\n",
        "        results.append(res)\n",
        "\n",
        "        # Show one-line summary per item\n",
        "        ext = res[\"extraction\"]\n",
        "        flag = \"üö®\" if ext.red_flags_present else \"‚úÖ\"\n",
        "        print(f\"     {flag} complaint='{ext.chief_complaint or 'N/A'}' \"\n",
        "              f\"| severity='{ext.severity or 'N/A'}' \"\n",
        "              f\"| confidence={res['source_confidence']:.2f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def export_batch_results(results: list, filepath: str = \"model_b_extractions.json\"):\n",
        "    \"\"\"Save batch results to a JSON file and download it.\"\"\"\n",
        "    export_data = {\n",
        "        \"timestamp\"  : datetime.datetime.now().isoformat(),\n",
        "        \"model\"      : GEMINI_MODEL_NAME,\n",
        "        \"total\"      : len(results),\n",
        "        \"red_flags\"  : sum(1 for r in results if r[\"extraction\"].red_flags_present),\n",
        "        \"extractions\": [\n",
        "            {\n",
        "                \"index\"             : i + 1,\n",
        "                \"source_language\"   : r[\"source_language\"],\n",
        "                \"source_confidence\" : r[\"source_confidence\"],\n",
        "                \"extraction_success\": r[\"extraction_success\"],\n",
        "                \"error\"             : r.get(\"error\"),\n",
        "                \"extraction\"        : r[\"extraction_dict\"],\n",
        "            }\n",
        "            for i, r in enumerate(results)\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(export_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"\\n‚úÖ Saved {len(results)} extraction(s) to: {filepath}\")\n",
        "    print(f\"   Red flags detected: {export_data['red_flags']}\")\n",
        "\n",
        "    from google.colab import files\n",
        "    files.download(filepath)\n",
        "\n",
        "\n",
        "print(\"‚úÖ Batch processing and export functions defined.\")\n",
        "print()\n",
        "print(\"USAGE EXAMPLE:\")\n",
        "print(\"  transcripts = [\")\n",
        "print(\"    {'transcript': 'I have a headache...', 'source_language': 'english'},\")\n",
        "print(\"    {'transcript': 'Ndi n\\'ububabare...', 'source_language': 'kinyarwanda'},\")\n",
        "print(\"  ]\")\n",
        "print(\"  results = batch_extract(transcripts)\")\n",
        "print(\"  export_batch_results(results)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-11",
      "metadata": {
        "id": "section-11"
      },
      "source": [
        "---\n",
        "## üìä Section 11 ‚Äî Prompt Calibration & Validation Workflow\n",
        "\n",
        "Use this section to calibrate prompts against your manually annotated local dataset. Feed in annotated examples and compare model output against gold labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "calibration",
      "metadata": {
        "id": "calibration"
      },
      "outputs": [],
      "source": [
        "def evaluate_against_annotations(\n",
        "    annotated_examples: list,\n",
        "    fields_to_evaluate: list = [\"chief_complaint\", \"severity\", \"body_part\"],\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Compare model extractions against manually annotated gold labels.\n",
        "\n",
        "    Args:\n",
        "        annotated_examples : List of dicts, each with:\n",
        "            {\n",
        "              'transcript'   : str,\n",
        "              'gold_labels'  : { 'chief_complaint': ..., 'severity': ..., ... }\n",
        "            }\n",
        "        fields_to_evaluate : Which fields to score.\n",
        "\n",
        "    Returns:\n",
        "        Dict with per-field match rates and full comparison table.\n",
        "    \"\"\"\n",
        "    field_matches  = {f: 0 for f in fields_to_evaluate}\n",
        "    field_totals   = {f: 0 for f in fields_to_evaluate}\n",
        "    comparisons    = []\n",
        "\n",
        "    for i, ex in enumerate(annotated_examples):\n",
        "        print(f\"\\n  [{i+1}/{len(annotated_examples)}] Evaluating...\")\n",
        "        result   = extract_clinical_information(ex[\"transcript\"], verbose=False)\n",
        "        pred     = result[\"extraction_dict\"]\n",
        "        gold     = ex[\"gold_labels\"]\n",
        "        row      = {\"index\": i+1, \"transcript_preview\": ex[\"transcript\"][:80]}\n",
        "\n",
        "        for fld in fields_to_evaluate:\n",
        "            gold_val = str(gold.get(fld, \"\")).strip().lower()\n",
        "            pred_val = str(pred.get(fld, \"\")).strip().lower()\n",
        "            # Soft match: gold label contained in prediction or exact match\n",
        "            match    = (gold_val in pred_val) or (gold_val == pred_val)\n",
        "            field_matches[fld] += int(match)\n",
        "            field_totals[fld]  += 1\n",
        "            row[f\"{fld}_gold\"]  = gold_val\n",
        "            row[f\"{fld}_pred\"]  = pred_val\n",
        "            row[f\"{fld}_match\"] = \"‚úÖ\" if match else \"‚ùå\"\n",
        "            print(f\"     {fld}: gold='{gold_val}' | pred='{pred_val}' | {'‚úÖ' if match else '‚ùå'}\")\n",
        "\n",
        "        comparisons.append(row)\n",
        "\n",
        "    # Summary\n",
        "    print(\"\\n\" + \"‚îÄ\" * 50)\n",
        "    print(\" CALIBRATION SUMMARY\")\n",
        "    print(\"‚îÄ\" * 50)\n",
        "    summary = {}\n",
        "    for fld in fields_to_evaluate:\n",
        "        rate = field_matches[fld] / max(field_totals[fld], 1)\n",
        "        summary[fld] = round(rate, 3)\n",
        "        bar = \"‚ñà\" * int(rate * 20) + \"‚ñë\" * (20 - int(rate * 20))\n",
        "        print(f\"  {fld:<28}: {bar}  {rate*100:.1f}%\")\n",
        "\n",
        "    return {\"per_field_accuracy\": summary, \"comparisons\": comparisons}\n",
        "\n",
        "\n",
        "# ‚îÄ‚îÄ Example annotated set ‚Äî replace with your real annotations ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "SAMPLE_ANNOTATED = [\n",
        "    {\n",
        "        \"transcript\": \"I've had a headache for two days, mostly on the right side. It's quite severe.\",\n",
        "        \"gold_labels\": {\"chief_complaint\": \"headache\", \"duration\": \"two days\", \"severity\": \"severe\", \"body_part\": \"head\"},\n",
        "    },\n",
        "    {\n",
        "        \"transcript\": \"My stomach has been hurting since this morning. Moderate pain.\",\n",
        "        \"gold_labels\": {\"chief_complaint\": \"stomach pain\", \"duration\": \"since this morning\", \"severity\": \"moderate\", \"body_part\": \"stomach\"},\n",
        "    },\n",
        "]\n",
        "\n",
        "# Uncomment to run calibration:\n",
        "# calibration_results = evaluate_against_annotations(SAMPLE_ANNOTATED)\n",
        "\n",
        "print(\"‚úÖ Calibration framework defined.\")\n",
        "print(\"   Uncomment the last line to run with SAMPLE_ANNOTATED or your own dataset.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "notes-cell",
      "metadata": {
        "id": "notes-cell"
      },
      "source": [
        "---\n",
        "## üìù Notes & Design Decisions\n",
        "\n",
        "| Topic | Detail |\n",
        "|---|---|\n",
        "| **Temperature = 0.0** | Ensures deterministic, reproducible schema outputs ‚Äî essential for clinical consistency. |\n",
        "| **Red flag override** | A keyword vocabulary layer cross-checks Gemini's `red_flags_present` to catch any model misses. |\n",
        "| **No diagnosis constraint** | Enforced both in the system prompt and in downstream validation. The model sees no diagnosis instruction at all. |\n",
        "| **`additional_observations`** | Intentionally flexible ‚Äî preserves patient affect, contextual clues, and language-switch patterns that don't map to schema fields. |\n",
        "| **Kinyarwanda support** | Gemini 1.5 has multilingual support. Kinyarwanda extraction quality should be validated against your annotated set and the prompt refined if needed. |\n",
        "| **Low-confidence transcripts** | If `source_confidence < 0.5`, consider flagging the extraction result as provisional for doctor review. |\n",
        "| **Model swap** | Replace `gemini-1.5-flash` with `gemini-1.5-pro` in `GEMINI_MODEL_NAME` for higher extraction quality in production. |"
      ]
    }
  ]
}